{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OHLCV dataset into a Pandas Dataframe\n",
    "ohlcv_df = pd.read_csv(\n",
    "    Path(\"./Resources/emerging_markets_ohlcv.csv\"), \n",
    "    index_col='date', \n",
    "    infer_datetime_format=True, \n",
    "    parse_dates=True\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "ohlcv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the date index and close columns\n",
    "signals_df = ohlcv_df.loc[:, [\"close\"]]\n",
    "\n",
    "# Use the pct_change function to generate returns from close prices\n",
    "signals_df[\"Actual Returns\"] = signals_df[\"close\"].pct_change()\n",
    "\n",
    "# Drop all NaN values from the DataFrame\n",
    "signals_df = signals_df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate trading signals using short- and long-window SMA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the short window and long window\n",
    "short_window = 4\n",
    "long_window = 100\n",
    "\n",
    "# Generate the fast and slow simple moving averages (4 and 100 days, respectively)\n",
    "signals_df['SMA_Fast'] = signals_df['close'].rolling(window=short_window).mean()\n",
    "signals_df['SMA_Slow'] = signals_df['close'].rolling(window=long_window).mean()\n",
    "\n",
    "signals_df = signals_df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new Signal column\n",
    "signals_df['Signal'] = 0.0\n",
    "\n",
    "# When Actual Returns are greater than or equal to 0, generate signal to buy stock long\n",
    "signals_df.loc[(signals_df['Actual Returns'] >= 0), 'Signal'] = 1\n",
    "\n",
    "# When Actual Returns are less than 0, generate signal to sell stock short\n",
    "signals_df.loc[(signals_df['Actual Returns'] < 0), 'Signal'] = -1\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "signals_df['Signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the strategy returns and add them to the signals_df DataFrame\n",
    "signals_df['Strategy Returns'] = signals_df['Actual Returns'] * signals_df['Signal'].shift()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(signals_df.head())\n",
    "display(signals_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Strategy Returns to examine performance\n",
    "(1 + signals_df['Strategy Returns']).cumprod().plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a copy of the sma_fast and sma_slow columns to a features DataFrame called X\n",
    "X = signals_df[['SMA_Fast', 'SMA_Slow']].shift().dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target set selecting the Signal column and assiging it to y\n",
    "y = signals_df['Signal']\n",
    "\n",
    "# Review the value counts\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features DataFrames\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the SVC classifier model from SKLearn's support vector machine (SVM) learning method to fit the training data and make predictions based on the testing data. Review the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SVM, instantiate SVC classifier model instance\n",
    "svm_model = svm.SVC()\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "svm_testing_report = classification_report(y_test, svm_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(svm_testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty predictions DataFrame:\n",
    "\n",
    "# Create a predictions DataFrame\n",
    "predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "predictions_df['Predicted'] = svm_pred\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "predictions_df['Actual Returns'] = signals_df['Actual Returns']\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "predictions_df['Strategy Returns'] = (\n",
    "    predictions_df['Actual Returns'] * predictions_df['Predicted']\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "display(predictions_df.head())\n",
    "display(predictions_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "(1 + predictions_df[['Actual Returns', 'Strategy Returns']]).cumprod().hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a new classifier from SKLearn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Initiate the model instance\n",
    "ab_model = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the training data\n",
    "ab_model = ab_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the testing dataset to generate the predictions for the new model\n",
    "ab_pred = ab_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "ab_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "ab_testing_report = classification_report(y_test, ab_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(ab_testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty predictions DataFrame:\n",
    "\n",
    "# Create a predictions DataFrame\n",
    "ab_predictions_df = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "ab_predictions_df['AB Predicted'] = ab_pred\n",
    "\n",
    "# Add the actual returns to the DataFrame\n",
    "ab_predictions_df['Actual Returns'] = signals_df['Actual Returns']\n",
    "\n",
    "# Add the strategy returns to the DataFrame\n",
    "ab_predictions_df['AB Strategy Returns'] = (\n",
    "    ab_predictions_df['Actual Returns'] * ab_predictions_df['AB Predicted']\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "display(ab_predictions_df.head())\n",
    "display(ab_predictions_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(1 + ab_predictions_df[['Actual Returns', 'AB Strategy Returns']]).cumprod().hvplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
